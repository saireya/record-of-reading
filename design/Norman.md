# Norman[『The design of everyday things』](urn:isbn:0465050654)
- Because much of the design is done by engineers who are experts in technology but limited in their understanding of people. “We are people ourselves,” they think, “so we understand people.” But in fact, we humans are amazingly complex. Those who have not studied human behavior often think it is pretty simple.

- As I watched people struggle with technology, it became clear that the difficulties were caused by the technology, not the people.

- even experts make errors. So we must design our machines on the assumption that people will make errors.

# Affordance
**affordance**: the *relationship* between a *physical object* and a *person* (not a property) (p.11)
- An affordance is a relationship between the properties of an object and the capabilities of the agent that determine just *how the object could possibly be used*.
- Whether an affordance exists depends upon the properties of both the object and the agent.
- the physical objects conveyed important information about *how people could interact with them*, a property he named “affordance.” (p.12)


# Signifier
**signifier**: some means of signaling its presence (p.11)
- "that is not an affordance. That is a way of communicating where the touch should be. You are communicating where to do the touching: the affordance of touching exists on the entire screen: you are trying to signify where the touch should take place. That’s not the same thing as saying what action is possible."

- all the senses work together, that we pick up information about the world by the combined result of all of them.

- visible affordances provide strong clues to the operations of things.
- Perceived affordances help people figure out what actions are possible without the need for labels or instructions. I call the signaling component of affordances signifiers.

- **Affordances** determine *what actions are possible*. **Signifiers** communicate *where the action should take place*.
- The signifier is an important communication device to the recipient, whether or not communication was intended. It doesn’t matter whether the useful signal was deliberately placed or whether it is incidental:


# Mapping
**Mapping**: the relationship between the elements of two sets of things.
- When the mapping uses spatial correspondence between the layout of the controls and the devices being controlled, it is easy to determine how to use them.
- It doesn’t matter whether these conceptual models are accurate: what matters is that they provide a *clear way of remembering and understanding the mappings*.
- Natural mapping, by which I mean taking advantage of spatial analogies, leads to immediate understanding.
- there are many mappings that feel “natural” but in fact are *specific to a particular culture*: what is natural for one culture is not necessarily natural for another.

# Feedback
**Feedback**: communicating the *results of an action*
- Feedback must be: *immediate*, *informative*, *planned*, *prioritized*

**Feedforward**: the information that helps answer questions of execution (doing) (p.72)
**Feedback**: the information that aids in understanding what has happened

Both feedback and feedforward need to be presented in a form that is *readily interpreted by the people using the system*.
The presentation has to match how people view the goal they are trying to achieve and their expectations. Information must match human needs.

# Conceptual model
**Conceptual model**: an *explanation*, usually highly simplified, of how something works.
- **Mental models**: the conceptual models in people’s minds that represent their understanding of how things work
- *Different people may hold different mental models* of the same item.
- The major clues to how things work come from their perceived structure—in particular from signifiers, affordances, constraints, and mappings.
- good conceptual model allows us to *predict* the effects of our actions.
- There is *no need to understand the underlying physics or chemistry* of each device we own, just the relationship between the controls and the outcomes.

**System image**: information available to us, e.g.
- what the device looks like
- what we know from using similar things in the past
- what was told to us in the sales literature, by salespeople and advertisements, by articles we may have read, by the product website and instruction manuals

It is *up to the designer to provide the appropriate information* to make the product understandable and usable.

Why do we need to know about the human mind? Because things are designed to be used by people, and without a deep understanding of people, the designs are apt to be faulty, difficult to use, difficult to understand.

Even if you knew you knew, but couldn’t quite recall it, you didn’t know how you knew that, or what was happening as you tried to remember.

**Cognition** provides understanding: emotion provides value judgments
- A human without a working emotional system has difficulty making choices.
- A human without a cognitive system is dysfunctional.


*To fail is to learn*: we learn more from our failures than from our successes.

Machines are not people
- They can’t communicate and understand the same way we do
- Designers have a special obligation to ensure that the *behavior of machines is understandable to the people* who interact with them

Humans are particularly bad at this, yet when they fail to meet the arbitrary, inhuman requirements of machines, we call it *human error*. No, it is *design error*.


some people firmly believe that it is the top button and some, just as firmly, believe it is the bottom button. Everyone is surprised to learn that someone else might think differently.

But why couldn’t the past be in front of us and the future behind? Does that sound strange? Why? We can see what is in front of us, but not what is behind, just as we can remember what happened in the past, but we can’t remember the future.

One way of *overcoming the fear of the new* is to make it look like *the old*.

# Error
Errors have two major forms:
- **Slips** occur when the goal is correct, but the required actions are not done properly: the execution is flawed.
- **Mistakes** occur when the goal or plan is wrong.

In many cases the *interruptions come from outside the system*, where the designer has no control.

detailed analyses of the intended group are necessary.

the iterative method of human-centered design, where the process is circular, with continual refinement, continual change, and encouragement of backtracking, rethinking early decisions.

critical knowledge about project decisions and methods are in the form we call *implicit knowledge*; that is, within the heads of the workers. *When workers leave, their implicit knowledge goes with them*.

The traditional metal vegetable peeler is shown on the left: inexpensive, but uncomfortable. The OXO peeler that revolutionized the industry is shown on the right. The result of this revolution is shown in the middle (p.244)

In an earlier era, there was close coupling between designers and users. Today, they are *separated* by barriers (p.260)
